{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-20T08:28:12.971888100Z",
     "start_time": "2024-02-20T08:28:08.469445800Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pytrends.request import TrendReq\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from newspaper import Article\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.collocations import BigramAssocMeasures, BigramCollocationFinder\n",
    "from nltk.collocations import TrigramAssocMeasures, TrigramCollocationFinder\n",
    "from nltk.collocations import QuadgramAssocMeasures, QuadgramCollocationFinder\n",
    "import statistics\n",
    "import collections\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Cargar las variables de entorno desde el archivo .env\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T08:28:15.079826500Z",
     "start_time": "2024-02-20T08:28:15.057575700Z"
    }
   },
   "id": "fd36f0c2b343ebda"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\gabriel.hernan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\gabriel.hernan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\gabriel.hernan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T15:57:40.519169Z",
     "start_time": "2024-02-19T15:57:40.513978200Z"
    }
   },
   "id": "8c8c1595892bf45e"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      value formattedValue                                        topic_title  \\\n",
      "0     78450        Aumento                        Generador de imágenes de IA   \n",
      "1     22000        Aumento                                    Marcela Mistral   \n",
      "2     14650        Aumento                       Leonardo Interactive Pty Ltd   \n",
      "3       200         +200 %                                               NSFW   \n",
      "4        50          +50 %                                      Renderización   \n",
      "5        40          +40 %                                            Censura   \n",
      "6   2043300        Aumento                                          Marketing   \n",
      "7     58600        Aumento                                     Tasa de rebote   \n",
      "8     42800        Aumento                                          Propiedad   \n",
      "9     35250        Aumento                          Cualificación profesional   \n",
      "10    34450        Aumento                                Universidad Harvard   \n",
      "11    31800        Aumento  Honeywell XNX XNX-RMAV-NNIV1 Universal Transmi...   \n",
      "12    28850        Aumento                                          Hootsuite   \n",
      "13    16200        Aumento                                      Mapa de calor   \n",
      "14    15900        Aumento                                  Púrpura Analytics   \n",
      "15    15750        Aumento                                Carrera profesional   \n",
      "16    11650        Aumento                     Indicador clave de rendimiento   \n",
      "17     1000       +1,000 %                                    Radiotransmisor   \n",
      "18      350         +350 %                                       Análisis web   \n",
      "19      180         +180 %                                              React   \n",
      "20      160         +160 %                                      Entrenamiento   \n",
      "21      160         +160 %                                             Cognos   \n",
      "22      150         +150 %                                     Salesforce.com   \n",
      "23      140         +140 %                                         Red social   \n",
      "24      100         +100 %                                               XNXX   \n",
      "25      100         +100 %                                Honeywell Analytics   \n",
      "26       90          +90 %                                Honeywell Analytics   \n",
      "27       60          +60 %                                            Informe   \n",
      "28       40          +40 %                                            Usuario   \n",
      "29   768650        Aumento                                           Software   \n",
      "30   430450        Aumento                                            Flutter   \n",
      "31   226350        Aumento                                           Proyecto   \n",
      "32      250         +250 %             Proceso para el desarrollo de software   \n",
      "33      140         +140 %                             Aplicación informática   \n",
      "34    47800        Aumento                                           Palworld   \n",
      "35    45050        Aumento                                      Globalización   \n",
      "36    44950        Aumento                                 Smart Technologies   \n",
      "37    35200        Aumento                                          Seguridad   \n",
      "38    32600        Aumento                                               Dell   \n",
      "39    30700        Aumento                             Industria farmacéutica   \n",
      "40    29150        Aumento                                         Smart Tech   \n",
      "41    25550        Aumento                   NACHI TECHNOLOGY MEXICO SA DE CV   \n",
      "42      450         +450 %                                  Micron Technology   \n",
      "43      300         +300 %                                             Cantón   \n",
      "44      250         +250 %                   KTH Real Instituto de Tecnología   \n",
      "45      200         +200 %  ZF Suspension Technology Guadalajara S.A. de C.V.   \n",
      "46      190         +190 %                              Instituto tecnológico   \n",
      "47      150         +150 %                                              Intel   \n",
      "48      140         +140 %                                             Micron   \n",
      "49      120         +120 %                              Definitive Technology   \n",
      "50      120         +120 %                                          Hong Kong   \n",
      "51       50          +50 %                     Intel Rapid Storage Technology   \n",
      "\n",
      "                                           topic_type  \\\n",
      "0                                          Aplicación   \n",
      "1   Presentadora de televisión ‧ Esposa de Poncho ...   \n",
      "2                                             Empresa   \n",
      "3                                                Tema   \n",
      "4                               Categoría de software   \n",
      "5                                                Tema   \n",
      "6                                                Tema   \n",
      "7                                                Tema   \n",
      "8                                                Tema   \n",
      "9                                Título universitario   \n",
      "10    Universidad privada en Cambridge, Massachusetts   \n",
      "11                                    Detector de gas   \n",
      "12                                            Empresa   \n",
      "13                                               Tema   \n",
      "14              Oficinas de empresa en Mérida, México   \n",
      "15                                               Tema   \n",
      "16                                               Tema   \n",
      "17                                               Tema   \n",
      "18                                               Tema   \n",
      "19                                         Aplicación   \n",
      "20                                               Tema   \n",
      "21                                           Compañía   \n",
      "22                                            Empresa   \n",
      "23                                   Campo de estudio   \n",
      "24                                          Sitio web   \n",
      "25                                               Tema   \n",
      "26                                            Empresa   \n",
      "27                                               Tema   \n",
      "28                                        Informática   \n",
      "29                                               Tema   \n",
      "30                                           Software   \n",
      "31                                               Tema   \n",
      "32                                               Tema   \n",
      "33                                   Tipo de software   \n",
      "34                                         Videojuego   \n",
      "35                                               Tema   \n",
      "36                                 Cadena de software   \n",
      "37                                               Tema   \n",
      "38                                               Tema   \n",
      "39                                               Tema   \n",
      "40                                               Tema   \n",
      "41      Fábrica en Parque Industrial Aerotech, México   \n",
      "42                                            Empresa   \n",
      "43                                    Ciudad en China   \n",
      "44                   Universidad en Estocolmo, Suecia   \n",
      "45                                               Tema   \n",
      "46                                    Tipo de escuela   \n",
      "47                                               Tema   \n",
      "48                                               Tema   \n",
      "49                                               Tema   \n",
      "50                     Región administrativa especial   \n",
      "51                                               Tema   \n",
      "\n",
      "                       keyword  \n",
      "0                           ia  \n",
      "1                           ia  \n",
      "2                           ia  \n",
      "3                           ia  \n",
      "4                           ia  \n",
      "5                           ia  \n",
      "6   search engine optimization  \n",
      "7                    analytics  \n",
      "8                    analytics  \n",
      "9                    analytics  \n",
      "10                   analytics  \n",
      "11                   analytics  \n",
      "12                   analytics  \n",
      "13                   analytics  \n",
      "14                   analytics  \n",
      "15                   analytics  \n",
      "16                   analytics  \n",
      "17                   analytics  \n",
      "18                   analytics  \n",
      "19                   analytics  \n",
      "20                   analytics  \n",
      "21                   analytics  \n",
      "22                   analytics  \n",
      "23                   analytics  \n",
      "24                   analytics  \n",
      "25                   analytics  \n",
      "26                   analytics  \n",
      "27                   analytics  \n",
      "28                   analytics  \n",
      "29             web development  \n",
      "30             web development  \n",
      "31             web development  \n",
      "32             web development  \n",
      "33             web development  \n",
      "34                  technology  \n",
      "35                  technology  \n",
      "36                  technology  \n",
      "37                  technology  \n",
      "38                  technology  \n",
      "39                  technology  \n",
      "40                  technology  \n",
      "41                  technology  \n",
      "42                  technology  \n",
      "43                  technology  \n",
      "44                  technology  \n",
      "45                  technology  \n",
      "46                  technology  \n",
      "47                  technology  \n",
      "48                  technology  \n",
      "49                  technology  \n",
      "50                  technology  \n",
      "51                  technology  \n"
     ]
    }
   ],
   "source": [
    "# Initialize pytrends request\n",
    "pytrends = TrendReq(hl='es-MX', tz=360)\n",
    "\n",
    "# List of keywords we want to analyze\n",
    "keywords_list = [\"ia\", \"search engine optimization\", \"analytics\", \"web development\", \"technology\" ]\n",
    "\n",
    "# Initialize an empty DataFrame to store the results\n",
    "all_rising_topics_df = pd.DataFrame()\n",
    "\n",
    "# Iterate over each keyword in the list\n",
    "for keyword in keywords_list:\n",
    "    # Build payload for the keyword\n",
    "    pytrends.build_payload([keyword], cat=0, timeframe=\"today 3-m\", geo=\"MX\")\n",
    "    \n",
    "    # Get related topics for the keyword\n",
    "    related_topics = pytrends.related_topics()\n",
    "    \n",
    "    # Extract rising topics for the keyword, if available\n",
    "    if related_topics and keyword in related_topics and 'rising' in related_topics[keyword]:\n",
    "        rising_df = related_topics[keyword]['rising'].copy()  # Make a copy of the rising topics DataFrame\n",
    "        # Normalize the DataFrame by dropping unnecessary columns, if desired\n",
    "        rising_df = rising_df.drop(columns=['link', 'topic_mid'])\n",
    "        # Add a 'keyword' column to indicate which keyword the topics belong to\n",
    "        rising_df['keyword'] = keyword\n",
    "        # Append the rising topics DataFrame to the main all_rising_topics_df\n",
    "        all_rising_topics_df = pd.concat([all_rising_topics_df, rising_df], ignore_index=True)\n",
    "\n",
    "# Display the final concatenated DataFrame of rising topics for all keywords\n",
    "print(all_rising_topics_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T08:28:26.127787600Z",
     "start_time": "2024-02-20T08:28:18.939264700Z"
    }
   },
   "id": "d46b8093373c363a"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "all_rising_topics_df.to_csv('rising_topics.csv', index=False, encoding='utf-8-sig')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T08:28:29.413887200Z",
     "start_time": "2024-02-20T08:28:29.399380200Z"
    }
   },
   "id": "b94369d9e95e6728"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Se asume que all_rising_topics_df es un DataFrame que contiene las tendencias y que ya está importado o disponible en tu código.\n",
    "\n",
    "country = \"ES\"\n",
    "\n",
    "# Función modificada para recibir una lista de consultas en lugar de una sola\n",
    "\n",
    "def google_custom_search_df(query, country):\n",
    "    API_CUSTOM_SEARCH_KEY = os.getenv('API_CUSTOM_SEARCH_KEY')\n",
    "    API_CUSTOM_SEARCH_ID = os.getenv('API_CUSTOM_SEARCH_ID')\n",
    "    \n",
    "    # Crear un DataFrame vacío para almacenar todos los resultados concatenados\n",
    "    all_search_results_df = pd.DataFrame()\n",
    "\n",
    "    # Iterar sobre la lista de consultas\n",
    "    for q in query:\n",
    "        # URL request con la consulta actual\n",
    "        url = f\"https://www.googleapis.com/customsearch/v1?key={API_CUSTOM_SEARCH_KEY}&cx={API_CUSTOM_SEARCH_ID}&q={q}&start=1&gl={country}\"\n",
    "        data = requests.get(url).json()\n",
    "\n",
    "        # Extraer lo que contiene items:\n",
    "        items = data.get(\"items\")\n",
    "\n",
    "        # Si hay resultados, crear un DataFrame y añadirlo al DataFrame principal\n",
    "        if items:\n",
    "            df = pd.DataFrame(items, columns=['title', 'link'])\n",
    "            df['query'] = q  # Añadir columna con la consulta para referencia\n",
    "            all_search_results_df = pd.concat([all_search_results_df, df], ignore_index=True)\n",
    "            \n",
    "    # Después de concatenar los resultados de búsqueda, imprime para verificar la estructura\n",
    "    print(\"all_search_results_df estructura:\", all_search_results_df.columns)\n",
    "    print(all_search_results_df.head())  # Muestra las primeras filas para verificar\n",
    "\n",
    "    return all_search_results_df\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T10:07:22.210927100Z",
     "start_time": "2024-02-20T10:07:22.210927100Z"
    }
   },
   "id": "2253bc3943b3d1dd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Función de scraping adaptada para manejar errores y vacíos\n",
    "# Utiliza tu código de scraping existente\n",
    "def scrape_article(url):\n",
    "    try:\n",
    "        article = Article(url)\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        if not article.text:\n",
    "            # Si Newspaper no pudo obtener el texto, intenta con BeautifulSoup\n",
    "            page = requests.get(url)\n",
    "            soup = BeautifulSoup(page.content, 'html.parser')\n",
    "            \n",
    "            # Busca contenido en etiquetas <p> o <div>\n",
    "            article_text = ' '.join([p.get_text() for p in soup.find_all(['p', 'div'])])\n",
    "            \n",
    "            return article_text\n",
    "        return article.text\n",
    "    except Exception as e:\n",
    "        print(f\"Error al scrapear el artículo: {str(e)}\")\n",
    "        return \"\"\n",
    "\n",
    "# Función para aplicar scraping a una lista de artículos y crear una columna de texto extraído\n",
    "def scrape_articles_in_dataframe(df):\n",
    "    scraped_texts = []  # Aquí almacenaremos el texto de los artículos\n",
    "\n",
    "    for url in df['link']:\n",
    "        scraped_text = scrape_article(url)\n",
    "        scraped_texts.append(scraped_text)\n",
    "\n",
    "    # Agregamos los textos como una nueva columna en el DataFrame\n",
    "    df['scraped_text'] = scraped_texts\n",
    "\n",
    "    return df\n",
    "\n",
    "# Utilizando el DataFrame de tendencias, extrae los títulos de tendencia como consultas\n",
    "trend_queries = all_rising_topics_df['topic_title'].tolist()\n",
    "\n",
    "# Usa la función modificada con la lista de consultas\n",
    "all_search_results_df = google_custom_search_df(trend_queries, country)\n",
    "\n",
    "# Realiza el scraping de los contenidos de los resultados de búsqueda y añade texto raspado a DataFrame\n",
    "all_search_results_df = scrape_articles_in_dataframe(all_search_results_df)\n",
    "\n",
    "# A este punto, all_search_results_df contendrá los resultados de búsqueda y el texto de cada artículo raspado, con una columna adicional 'query' que indica la consulta original."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "109d9d99791a395c"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "#--------------- GOOGLE CUSTOM SEARCH: nos conectamos a la API de Google a través de generar un buscador global(tambien puede ser para un site en especifico)\n",
    "\n",
    "query = \"marketing digital\"\n",
    "country = \"ES\"\n",
    "leng = \"ES\"\n",
    "\n",
    "\n",
    "def google_custom_search_df(query, country=\"ES\"):\n",
    "    API_CUSTOM_SEARCH_KEY = os.getenv('API_CUSTOM_SEARCH_KEY')\n",
    "    API_CUSTOM_SEARCH_ID = os.getenv('API_CUSTOM_SEARCH_ID')\n",
    "\n",
    "    # URL request\n",
    "    url = f\"https://www.googleapis.com/customsearch/v1?key={API_CUSTOM_SEARCH_KEY}&cx={API_CUSTOM_SEARCH_ID}&q={query}&start=1&gl={country}\"\n",
    "    data = requests.get(url).json()\n",
    "\n",
    "    # Extraer lo que contiene items:\n",
    "    items = data.get(\"items\")\n",
    "\n",
    "    # Crear un DataFrame con los resultados de la búsqueda\n",
    "    df = pd.DataFrame(items, columns=['title', 'link'])\n",
    "\n",
    "    return df\n",
    "\n",
    "df = google_custom_search_df(query, country)\n",
    "\n",
    "\n",
    "#-------------------SCRAPING del texto de los articulos de las 10 primeras posiciones de Google SERP\n",
    "\n",
    "#Extraer el texto de los articulos con la libreria newspapper y, en su defecto, con beautiful soup\n",
    "\n",
    "def scrape_article(url):\n",
    "    try:\n",
    "        article = Article(url)\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        if not article.text:\n",
    "            # Si Newspaper no pudo obtener el texto, intenta con BeautifulSoup\n",
    "            page = requests.get(url)\n",
    "            soup = BeautifulSoup(page.content, 'html.parser')\n",
    "            \n",
    "            # Busca contenido en etiquetas <p> o <div>\n",
    "            article_text = ' '.join([p.get_text() for p in soup.find_all(['p', 'div'])])\n",
    "            \n",
    "            return article_text\n",
    "        return article.text\n",
    "    except Exception as e:\n",
    "        print(f\"Error al scrapear el artículo: {str(e)}\")\n",
    "        return \"\"\n",
    "\n",
    "def scrape_articles_in_dataframe(df):\n",
    "    scraped_texts = []  # Aquí almacenaremos el texto de los artículos\n",
    "\n",
    "    for url in df['link']:\n",
    "        scraped_text = scrape_article(url)\n",
    "        scraped_texts.append(scraped_text)\n",
    "\n",
    "    # Agregamos los textos como una nueva columna en el DataFrame\n",
    "    df['scraped_text'] = scraped_texts\n",
    "\n",
    "    return df\n",
    "\n",
    "# Llama a la función scraping de los artículos\n",
    "df = scrape_articles_in_dataframe(df)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T16:28:20.294868700Z",
     "start_time": "2024-02-19T16:28:20.289911900Z"
    }
   },
   "id": "a848d427fe696b1d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "13e3fbeef985591c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
